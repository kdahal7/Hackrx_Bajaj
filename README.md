# ðŸ“˜ LLM-Powered Query-Retrieval System  

A smart system that extracts text from PDF documents, performs semantic search, and answers user questions using **Groq LLMs**. Optimized for **insurance/legal documents** with caching, parallel processing, and high accuracy.  

---

## âœ¨ Features
- ðŸš€ FastAPI backend with async & caching  
- ðŸ“‘ PDF text extraction (PyMuPDF)  
- ðŸ”Ž Semantic Search with FAISS + Sentence Transformers  
- ðŸ§  Smart Caching Engine (reduces redundant LLM API calls)  
- âš¡ Parallel question answering for speed & scale  
- ðŸ”’ Secure API with Bearer token authentication  

---

## âœ… Prerequisites
- Python **3.10 or 3.11**  
- `git` installed  
- Internet connection (for downloading PDFs and LLM API calls)  
- (Optional) **Groq API key** for best answers. Without it, fallback extraction still works.  

---

## ðŸ›  Step 1: Clone the Repository
```bash
git clone https://github.com/your-username/your-repo.git
cd your-repo

```
## ðŸ›  Step 2: Create Virtual Environment
```bash
python -m venv .venv
.venv\Scripts\Activate.ps1
Activate it:

Linux / macOS:
source .venv/bin/activate

Windows (PowerShell):
.venv\Scripts\Activate.ps1
```

## ðŸ›  Step 3: Install Dependencies
```bash
## pip install --upgrade pip
pip install -r requirements.txt

```
## ðŸ›  Step 4: Create .env file
## In the project root, create a file called .env and add:
```bash
BEARER_TOKEN=super-secret-token-123   # Your chosen API token
GROQ_API_KEY=your_groq_api_key_here   # Optional (for LLM answers)
# Or multiple keys:
# GROQ_API_KEYS=key1,key2,key3
```

## ðŸ›  Step 5: Run the App

```bash
uvicorn app:app --reload
```

